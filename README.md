# ğŸ§  PyChat â€” AI-Powered Python Chatbot

PyChat is an **AI-driven Retrieval-Augmented Generation (RAG)** project that provides context-aware answers to Python programming questions.  
It combines intelligent web crawling, document indexing, and hybrid retrieval with an interactive web-based chat interface.  
The live chatbot is hosted here:  
ğŸ‘‰ **[https://pychat-jryk.onrender.com/](https://pychat-jryk.onrender.com/)**

---

## ğŸš€ Features

### ğŸ•·ï¸ Web Crawler
- Asynchronous multi-domain crawler using **Crawl4AI**.  
- Content filtering based on structure, word count, and code snippets.  
- Automatic deduplication with **SimHash** and SQLite.  
- Resumable checkpoints and robots.txt compliance.  

### ğŸ§© Indexing & Embeddings
- Smart text chunking with **RecursiveCharacterTextSplitter**.  
- Embeddings via **Jina AI (768-dim)** for consistency across environments.  
- Local or remote indexing into **Qdrant Cloud**.  
- Supports metadata (URL, title, quality score, word count, etc.).  

### ğŸ” Retrieval System
- **Hybrid retrieval** combining semantic search and BM25 keyword matching.  
- **Reranking** powered by **Jina AI** (cloud API fallback on Render).  
- **Groq LLM** used for final answer generation.  
- Query rewriting and factual verification pipeline.  
- Built-in metrics and Prometheus endpoint for performance tracking.  

### ğŸ’¬ Chat Interface
- Responsive single-page web UI built with **HTML + CSS + Vanilla JS**.  
- Chat input, response streaming, and source display.  
- Local conversation history and theme toggle.  
- Works directly with the FastAPI backend hosted on **Render**.  

---

## ğŸ—ï¸ Project Structure

```
PyChat/
â”‚
â”œâ”€â”€ crawler/
â”‚   â”œâ”€â”€ config_loader.py
â”‚   â”œâ”€â”€ content_processor.py
â”‚   â”œâ”€â”€ domain_worker.py
â”‚   â”œâ”€â”€ orchestrator.py
â”‚   â”œâ”€â”€ robots_handler.py
â”‚   â”œâ”€â”€ state_manager.py
â”‚   â”œâ”€â”€ models.py
â”‚   â””â”€â”€ url_utils.py
â”‚
â”œâ”€â”€ embeddings.py               # Embedding engine (local/Jina hybrid)
â”œâ”€â”€ indexer.py                  # Chunk â†’ embed â†’ index pipeline
â”œâ”€â”€ analytics.py                # Crawl and quality reports
â”œâ”€â”€ db_utils.py                 # SQLite for dedup & metadata
â”œâ”€â”€ quality_analyzer.py         # Content scoring
â”œâ”€â”€ migrate_to_qdrant.py        # Uploads Chroma vectors to Qdrant Cloud
â”‚
â”œâ”€â”€ rag_api/
â”‚   â”œâ”€â”€ main.py                 # FastAPI app
â”‚   â”œâ”€â”€ llm_client.py           # Groq API wrapper
â”‚   â”œâ”€â”€ retriever.py            # Hybrid Qdrant + BM25 retriever
â”‚   â”œâ”€â”€ prompt_builder.py       # Prompt assembly
â”‚   â”œâ”€â”€ classifier.py           # Query intent classifier
â”‚   â”œâ”€â”€ schemas.py              # Pydantic models
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ logging.py
â”‚       â””â”€â”€ cache.py
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ style.css
â”‚   â””â”€â”€ script.js
â”‚
â”œâ”€â”€ config.py                   # Global settings & environment loader
â”œâ”€â”€ run.py                      # CLI for crawl, index, serve, etc.
â”œâ”€â”€ ask.py                      # Command-line query tool
â”œâ”€â”€ sources.yaml                # Crawl seed configuration
â”œâ”€â”€ .env.example                # Environment template
â””â”€â”€ requirements.txt
```

---

## âš™ï¸ Setup

### 1. Clone
```bash
git clone https://github.com/yourusername/pychat.git
cd pychat
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

### 3. Configure Environment
Copy `.env.example` to `.env` and fill in:
```env
QDRANT_URL=https://your-qdrant-instance.qdrant.tech
QDRANT_API_KEY=your_qdrant_api_key
GROQ_API_KEY=your_groq_api_key
JINA_API_KEY=your_jina_api_key
```

### 4. Prepare Directories
```bash
mkdir -p data/checkpoints data/vectordb data/logs
```

---

## ğŸ•¸ï¸ Crawl Documentation

Edit `sources.yaml`:
```yaml
sources:
  python:
    - url: "https://docs.python.org/3/"
      max_pages: 2000
      quality_threshold: 45
```

Run:
```bash
python run.py crawl --max-pages 2000 --quality-threshold 45
```

Outputs cleaned content to `data/crawled.jsonl`.

---

## ğŸ§  Index and Upload

Create embeddings and index locally:
```bash
python run.py index
```

Migrate to Qdrant Cloud:
```bash
python migrate_to_qdrant.py
```

Qdrant will store **768-dim vectors** for Jina embeddings.

---

## ğŸ§© Start the API Server

```bash
python run.py serve
```

Then visit:
```
http://127.0.0.1:8000/docs
```

Endpoints:
- `/query` â€” RAG question answering  
- `/stats` â€” system info  
- `/prometheus` â€” metrics  
- `/health` â€” status  

---

## ğŸ’¬ Web Chat UI

With the backend running, open:
```
http://127.0.0.1:8000/
```

Ask questions such as:
> *â€œExplain Python decorators.â€*  
> *â€œHow do list comprehensions work?â€*  

PyChat retrieves relevant documentation, ranks it, and synthesizes an answer using Groq.

The same chatbot is live here:  
ğŸ‘‰ **[https://pychat-jryk.onrender.com/](https://pychat-jryk.onrender.com/)**

---

## ğŸ§ª CLI Tools

| Command | Description |
|----------|-------------|
| `python run.py crawl` | Crawl documentation |
| `python run.py index` | Create embeddings |
| `python run.py migrate` | Push to Qdrant |
| `python run.py serve` | Run FastAPI server |
| `python run.py query "..."` | CLI query mode |
| `python run.py analyze` | Generate analytics |
| `python run.py clean` | Clear data and checkpoints |
| `python ask.py "..."` | Direct Groq call |

---

## ğŸ§° Stack Overview

| Component | Technology |
|------------|-------------|
| **LLM** | Groq (Llama-3.1-8B-Instant) |
| **Embeddings** | Jina AI v2 Base (768-D) |
| **Vector DB** | Qdrant Cloud |
| **Crawler** | Crawl4AI + aiohttp + BeautifulSoup |
| **Backend** | FastAPI + Uvicorn |
| **Frontend** | HTML / CSS / JS |
| **Metrics** | Prometheus |
| **Orchestration** | Render (Web Service) |

---

## ğŸ§­ Highlights

- Modular pipeline: crawl â†’ process â†’ index â†’ query.  
- Local GPU support; automatic fallback to Jina Cloud on Render.  
- Hybrid retrieval with BM25 + semantic search.  
- Configurable models and weights via `.env`.  
- Persistent vector storage and checkpointing.  
- Built-in monitoring and logging.

---

## ğŸ§‘â€ğŸ’» Notes

- Python â‰¥ 3.10  
- GPU optional (auto-detects CUDA)  
- Works offline locally, cloud-optimized for Render deployment  

---

## ğŸ›¡ï¸ License
MIT License â€” see `LICENSE` for details.  

---

## ğŸŒŸ Credits
- [Jina AI](https://jina.ai)  
- [Qdrant Cloud](https://qdrant.tech)  
- [Groq Cloud](https://groq.com)  
- [SentenceTransformers](https://www.sbert.net)  
- [Crawl4AI](https://github.com/nidhaloff/crawl4ai)  
